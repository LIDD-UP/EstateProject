1:直接把代码上传到服务器，配置爬虫运行环境然后直接运行爬虫
    有点建议这种方式，因为这种大数据量的爬虫，网站的更新较快，不能把大量的时间做在部署上（这种方式可以结合telnet远程管理）

2：利用scrapyd进行部署
    不建立，但是也是一种方式，这种方式容易管理爬虫（可以通过浏览器查看爬虫运行情况）
3：利用docker部署
    1：需要redis 容器
    2：需要爬虫运行的容器，爬虫和相应的运行环境在一个容器里


4：突然发现程序有问题:每一个的搜索条件应该放到start_urls里面
用到scrapy-redis 的解决方案是，写一个脚本将start_urls先全部插入到redis里面，再启动爬虫

解决办法一：
redis 起始插入start_urls写成一个脚本；

这样就可以将redispush和爬虫的启动分离开，

解决办法二：
就是将插入和其中一个爬虫结合起来，

还有就是将这个脚本作为一个docker，但是有点奢侈，docker一个文件很大；


最终决定还是将这个文件结合到其中一个客户端爬虫的中，解决服务器资源；
























